{
  "hash": "70e4c5ff31606e2100ed7c593e3c6d37",
  "result": {
    "markdown": "---\ntitle: \"Variance estimation: ANCOVA RCT analysis (part 2)\"\nauthor: \"Dominic Magirr\"\ndate: \"2025-10-09\"\ncategories: [RCT]\n---\n\n\n\n\nIn my [previous post](https://dominicmagirr.github.io/blog/posts/variance_lm/variance_lm.html) on estimating the variance of treatment effect estimators based on linear regression models in RCTs, I perhaps suggested that the method described in [Ye et al. (2023)](https://doi.org/10.1080/01621459.2022.2049278) and implemented in [{RobinCar}](https://marlenabannick.com/RobinCar/) and [{RobinCar2}](https://openpharma.github.io/RobinCar2/main/) was (for one particular scenario) underestimating the variance by about 15\\%. I should clarify that (in this scenario) it only underestimates the *conditional* variance (conditional on the particular design matrix that I chose) by about 15\\%. It underestimates the *unconditional* variance (where we consider sampling a new design matrix for each hypothetical repetition of the experiment) by about 7\\%, as I'll show below.\n\n\nMy previous post contained some R code to simulate one trial and then analyze it in using a linear model with a couple of different methods of variance estimation. Here, I have simply copied that code into a function. I have added a couple of extra features: I calculate the variance with an additional two methods ([sandwich estimators HC0 and HC1](https://doi.org/10.1080/00031305.2000.10474549)), and I also calculate the variance inflation factor [(see Senn et al.,2024)](https://arxiv.org/pdf/2408.06760)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(RobinCar2)\n\n## simulate one trial \nsim_one_trial <- function(n, beta, x_seed = NULL){\n  \n  ## equal allocation\n  if (n %% 2 == 1) stop(\"n must be even\")\n  a <- rep(c(0, 1), each = n / 2)\n  \n  ## simulate covariates\n  p <- length(beta) - 2\n  set.seed(x_seed) ## choose a specific seed to fix X\n  X_star <- matrix(rnorm(n * p), nrow = n, ncol = p)\n  \n  ## design matrix\n  X <- cbind(1, a, X_star)\n  \n  ## store variance inflation factor\n  vif <- solve(t(X)%*%X)[2,2] / (4/n)\n  \n  ## simulate outcome\n  set.seed(NULL) ## reset random number seed\n  y <- rnorm(n, X%*%beta)\n  \n  ## data set\n  dat <- as.data.frame(cbind(y, X[,-1]))\n  dat$a <- as.factor(dat$a)\n  \n  ## fit model\n  fit <- lm(y ~ ., data = dat)\n  \n  ## point estimate\n  point_estimate <- fit$coef[2]\n  \n  ## Model based Var\n  var_model <- vcov(fit)[\"a1\", \"a1\"] \n\n  ## HC0\n  var_HC0 <- sandwich::vcovHC(fit, type = \"HC0\")[\"a1\", \"a1\"]\n  \n  ## HC1\n  var_HC1 <- sandwich::vcovHC(fit, type = \"HC1\")[\"a1\", \"a1\"]\n  \n  ## RobinCar2 Var\n  robin_fit <- robin_lm(as.formula(paste0(\"y ~ \", paste0(names(dat)[-1], collapse = \"+\"))),\n                        data = dat,\n                        treatment = a ~ sp(1))\n  \n  var_robin <- robin_fit$contrast$variance[1,1]\n  \n  return(c(point_estimate = point_estimate,\n           vif = vif,\n           var_model = var_model,\n           var_HC0 = var_HC0,\n           var_HC1 = var_HC1,\n           var_robin = var_robin))\n  \n}\n```\n:::\n\n\n\nNow I'll repeat what I did in the previous post 10,000 times and store the results. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n### simulate 10000 trials\nres <- purrr::map_df(rep(200, 1e4), sim_one_trial, beta = c(0, 0.2, rep(0.1, 7)))\n```\n:::\n\n\n\nIn this case I have used a new design matrix in each replication of the experiment. If I wanted to know the true *unconditional* variance of the point estimator, one thing I could do is look at the sample variance of the 10,000 point estimates,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar(res[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  point_estimate.a1\npoint_estimate.a1        0.02105605\n```\n:::\n:::\n\nBut in this scenario, because I know that the true residual standard deviation is $1$ (and therefore don't need to estimate this part), a more accurate estimate of the true *unconditional* variance of the point estimator is \n\n\n::: {.cell}\n\n```{.r .cell-code}\nest_true_var <- mean(res$vif) * 4 / 200\nest_true_var\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02073315\n```\n:::\n:::\n\n\n\nWe can now see whether the different variance estimators are correct on average across the 10,000 experiments\n\n\n::: {.cell}\n\n```{.r .cell-code}\nav_res <- colMeans(res)\nav_res[3:6]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n var_model    var_HC0    var_HC1  var_robin \n0.02074655 0.01979663 0.02072946 0.01930495 \n```\n:::\n:::\n\n\nThe method from {RobinCar2} is (in this scenario) underestimating the *unconditional* variance by about 7\\%\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunname(av_res[\"var_robin\"] / est_true_var)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9311152\n```\n:::\n:::\n\n\nLooking across the different estimators, the reason HC0 underestimates the \"true\" variance is that it doesn't pay a degrees of freedom penalty of $n / (n - 9)$ (there are 9 coefficients in total in this linear model). If we add this penalty we get\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunname(av_res[\"var_HC0\"] * 200 / (200 - 9) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02072946\n```\n:::\n:::\n\n\nwhich is exactly what HC1 does:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nav_res[\"var_HC1\"] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   var_HC1 \n0.02072946 \n```\n:::\n:::\n\n\nThe method in {RobinCar2} also doesn't fully adjust for the degrees of freedom, but applying a correction is still not sufficient to match the \"true\" variance \n\n\n::: {.cell}\n\n```{.r .cell-code}\nunname(av_res[\"var_robin\"] * (200 - 2) / (200 - 9) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02001246\n```\n:::\n:::\n\n\nthat's because it also ignores a term called the *variance inflation factor* [(see Senn et al.,2024)](https://arxiv.org/pdf/2408.06760). In this scenario, the expected value of the variance inflation factor (calculated using the simulations) is\n\n\n::: {.cell}\n\n```{.r .cell-code}\nav_res[\"vif\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     vif \n1.036657 \n```\n:::\n:::\n\n\nIf we were to multiply the RobinCar variance by the expected value of the variance inflation factor, as well as the degrees of freedom penalty, then we would get back to approximately the correct unconditional variance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunname(av_res[\"var_robin\"] * (200 - 2) / (200 - 9) * av_res[\"vif\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02074607\n```\n:::\n:::\n\n\n## Conditional inference\n\nIn my previous post, I chose a particular design matrix by fixing the seed to be `620` before I simulated the covariates. Now let's simulate the trial 10,000 times using that same design matrix...\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_620 <- purrr::map_df(rep(200, 1e4), sim_one_trial, beta = c(0, 0.2, rep(0.1, 7)), x_seed = 620)\n```\n:::\n\n\nAgain we can look at the 'true' conditional variance of the point estimator (where we condition on this particular design matrix)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nest_true_cond_var <- mean(res_620$vif) * 4 / 200\nest_true_cond_var\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02257612\n```\n:::\n:::\n\n\nand see how well the variance estimators do on average\n\n\n::: {.cell}\n\n```{.r .cell-code}\nav_res_620 <- colMeans(res_620)\nav_res_620[3:6]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n var_model    var_HC0    var_HC1  var_robin \n0.02252817 0.02146240 0.02247372 0.01925754 \n```\n:::\n:::\n\n\nHere, we see that the method in RobinCar is underestimating the *conditional* variance by about 15\\% as I suggested in my previous post. The reason for the 15\\% (versus the 7\\% unconditionally) is that I chose a particularly unbalanced design matrix where the variance inflation factor is about 12\\%.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nav_res_620[\"vif\"]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     vif \n1.128806 \n```\n:::\n:::\n\n\n\nIf we correct for this variance inflation factor, as well as the degrees of freedom, we would arrive back to approximately the right place\n\n\n::: {.cell}\n\n```{.r .cell-code}\nunname(av_res_620[\"var_robin\"] * (200 - 2) / (200 - 9) * av_res_620[\"vif\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02253471\n```\n:::\n:::\n\n\n\n# Comments\n\nThe RobinCar variance estimator targets the unconditional variance, so perhaps my previous post was a bit unfair and the 7\\% figure would have been a better starting point to discuss whether or not the difference to the model-based variance estimator is practically important. Then again, why take for granted that the unconditional variance is more important than the conditional variance? \n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}