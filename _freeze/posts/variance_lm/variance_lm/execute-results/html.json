{
  "hash": "f320b894a7ce9d1dec9360fcf21307b2",
  "result": {
    "markdown": "---\ntitle: \"Variance estimation: ANCOVA RCT analysis\"\nauthor: \"Dominic Magirr\"\ndate: \"2025-10-05\"\ncategories: [RCT]\n---\n\n\nConsider a 2-arm RCT (1:1 allocation) with a continuous outcome, total sample size 200 and seven baseline covariates. Consider a superpopulation set-up. The estimand is the (super) population average treatment effect $\\theta = E(Y(1) - Y(0))$. Estimation is performed via a linear regression working model\n\n$$E(Y_i \\mid A_i, X_{1,i},ldots,X_{7,i}) = \\beta_0 + \\theta A_i + \\beta_1 X_{1,i} + \\cdots + \\beta_7{X_{7,i}}$$\n\nso that $\\hat{\\theta}$ is the usual least squares estimator of $\\theta$. For example,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(620)\n\nn <- 200\np <- 7\n\n## simulate covariatesÂ \nX_star <- matrix(rnorm(n * p), nrow = n, ncol = p)\n\n## equal allocation\na <- rep(c(0, 1), each = n / 2)\n\n## design matrix\nX <- cbind(1, a, X_star)\n\n## true parameter values\nbeta <- c(0, 0.2, rep(0.1, p))\n\n## simulate outcome\ny <- rnorm(n, X%*%beta)\n\n## data set\ndat <- as.data.frame(cbind(y, a, X_star))\ndat$a <- as.factor(dat$a)\n\n## fit model\nfit <- lm(y ~ ., data = dat)\n\n## point estimate theta_hat\nfit$coef[2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       a1 \n0.1901536 \n```\n:::\n:::\n\n\nHow should we estimate the variance of $\\hat{\\theta}$? One option is the usual ANCOVA approach,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Model based Var\nvar_model <- vcov(fit)[\"a1\", \"a1\"]\nvar_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02338236\n```\n:::\n:::\n\n\nAlternatively, we could use an influence function approach, as for example described in [Ye et al. (2023) \"Toward Better Practice of Covariate Adjustment in Analyzing Randomized Clinical Trials\"](<https://doi.org/10.1080/01621459.2022.2049278>), which has the endorsement of being included in [recent FDA guidance](<https://www.fda.gov/regulatory-information/search-fda-guidance-documents/adjusting-covariates-randomized-clinical-trials-drugs-and-biological-products>), and is implemented in [{RobinCar2}](<https://openpharma.github.io/RobinCar2/main/>),\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(RobinCar2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'RobinCar2'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:base':\n\n    table\n```\n:::\n\n```{.r .cell-code}\n## RobinCar2 Var\nrobin_fit <- robin_lm(as.formula(paste0(\"y ~ \", paste0(names(dat)[-1], collapse = \"+\"))),\n                      data = dat,\n                      treatment = a ~ sp(1))\n\nvar_robin <- robin_fit$contrast$variance[1,1]\nvar_robin\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01998412\n```\n:::\n:::\n\n\nThis estimated variance is 15\\% smaller than the usual ANCOVA variance estimate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar_robin / var_model\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8546666\n```\n:::\n:::\n\n\nSame model, same data, 15\\% smaller estimated variance.\n\n## So what?\n\nThe methods included in {RobinCar2} are powerful and useful. I'm an advocate for using more covariate adjustment in the primary analysis of RCTs. I'm especially excited about the methods for [covariate adjustment involving time-to-event outcomes](<https://academic.oup.com/biomet/article-pdf/111/2/691/57467434/asad045.pdf>). They need to be used in the appropriate settings, however.\n\nIt's easy to say that's when \\$p\\$ is not too large, and \\$n\\$ is not too small. I chose this example to be somewhere on the boundary of what I would instinctively consider reasonable but can still lead to a dramatic difference between the model-based and influence function approaches.\n\nI'm slowly building an understanding of what's driving this difference. It's a combination of several factors: conditional vs unconditional inference, variance inflation factors [(see Senn et al.,2024)](<https://arxiv.org/pdf/2408.06760>), and a degrees of freedom correction. In large(ish) sample sizes each of these factors might not seem to make a huge difference in isolation, but together it could add up to a big difference.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}